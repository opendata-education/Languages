{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordcloud\n",
    "\n",
    "Word cloud is a visual representation of text data that can be shown for example in a shape of a cloud. The words in the cloud are typically represented in different colors and font-sizes. See an example of a word cloud below! \n",
    "\n",
    "![cloud](../images/opendata-cloud.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we are going to create a word cloud of our own. We are going to use ice cream stall reviews from Helsinki area as our data that we want to display. The aim is to:\n",
    "\n",
    "- Read the review data from a file\n",
    "- Clean the data such that it contains no stop words\n",
    "- Display the data in a word cloud that has a form of an ice cream\n",
    "\n",
    "Let's get to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the review data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing the data we need. The data is available on a csv-file called \"icecream_stall_reviews.csv\". It is a collection of ice cream stall reviews that have been [scraped](https://en.wikipedia.org/wiki/Web_scraping) from [foursquare.com](https://foursquare.com/explore?mode=url&near=Helsinki&nearGeoId=72057594038586161&q=Ice%20cream). To read it, we can use a python-library called [pandas](https://pandas.pydata.org/). The function [`read_csv()`]() can do the job for us if we know the path to the data file. The file is in the same directory as this notebook-file so we can use the name of the file as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Save the table to variable 'data'\n",
    "data = pd.read_csv('../data/icecream_stall_reviews.csv')\n",
    "\n",
    "# Let's read the first few lines of the file\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that our data consists of the name of the stall, review-text and a rating number. Our next task is to extract the review-texts from the table, tokenize them and then clean them. We have done similar task already on a previous exercise where we studied Shakespeare's Hamlet. Let's do the cleaning this time using some efficient [list comprehensions](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions) and [lambda](https://docs.python.org/3/reference/expressions.html#lambda)-expressions. Don't worry if these look too overwhelming, these are just a way to do things quicker.\n",
    "\n",
    "Let's get to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a new column \"review_lowercase\" that contains the review texts with all letters being lowercase.\n",
    "data['review_lowercase'] = data['Reviews'].apply(lambda x:\" \".join(word.lower() for word in x.split()))\n",
    "\n",
    "# Make a new column \"review_nopunct\" that contains the review texts with non-words and non-letters removed.\n",
    "data['review_nopunct'] = data['review_lowercase'].str.replace('[^\\w\\s]','') #Removes non words and letters\n",
    "\n",
    "# Make a new column \"review_nostopwords\" that contains the review texts with stop words removed.\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "data['review_nostopword'] = data['review_nopunct'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_words))\n",
    "\n",
    "# See how the data looks like\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a cleaned set of review-data to be displayed on our word cloud! To be able to do this, we need to import [wordcloud](https://amueller.github.io/word_cloud/)-package and [matplotlib](https://matplotlib.org/)-package for plotting. We also need to transform our list of reviews to a single text-string. The classes and functions we need in this sections are:\n",
    "\n",
    "- [`WordCloud`](https://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html)\n",
    "- [`generate()`](https://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html)\n",
    "- [`to_string()`](https://www.geeksforgeeks.org/python-pandas-series-to_string/)\n",
    "- [`imshow()`](https://matplotlib.org/3.3.3/api/_as_gen/matplotlib.pyplot.imshow.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Get the review column from data-table as single string.\n",
    "data_string = data['review_nostopword'].to_string()\n",
    "\n",
    "# Create a WordCloud object with a spesified size.\n",
    "wordcloud = WordCloud()\n",
    "\n",
    "# Generate the words to cloud from our data string\n",
    "wordcloud.generate(data_string)\n",
    "\n",
    "# Initialize the figure\n",
    "plt.figure (figsize = (10,10))\n",
    "\n",
    "# Show the word cloud\n",
    "plt.imshow(wordcloud)\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We see a wordcloud from our reviews now. However, there are still some extra words that perhaps we would not like to include in our cloud such as 'ice', 'cream', 'ive', 'take', 'tried' and 'try'. These were not included in the stop words we used. We can include them manually, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new column \"review_cleaned\" that contains the review texts with additional stop words removed.\n",
    "other_stopwords = ['ice','cream','ive','take','tried','try']\n",
    "data['review_cleaned'] = data['review_nostopword'].apply(lambda x: \" \".join(word for word in x.split() if word not in other_stopwords))\n",
    "\n",
    "# See how the data looks like now\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we also wanted to display the words in a shape of an ice cream. For this, we need an image of an ice cream to be used as a mask. The area we want our words to be in should be black in the image and the backgbround should be white. Therefore, we need a black icecream on a white background. This kind of image can be found in the file called \"icecream.png\". To open the image in python, we first need to use a module called [Image](https://pillow.readthedocs.io/en/stable/reference/Image.html) from [PIL](https://pillow.readthedocs.io/en/stable/index.html)-package and then transform it into an RGB-array using [`array()`](https://numpy.org/doc/stable/reference/generated/numpy.array.html) from [numpy](https://numpy.org/)-package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Open the image file\n",
    "image = Image.open('../images/icecream.png')\n",
    "\n",
    "# Transform the image into an RGB array\n",
    "icecream_mask = np.array(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make the word cloud by a similar manner as before, but adding some additional parameters to the WordCloud-object. Check the cell before for details!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cleaned review column from data-table as single string.\n",
    "data_string = data['review_cleaned'].to_string()\n",
    "\n",
    "# Make a WordCloud-object with specified mask, background color, contour width and contour color\n",
    "wordcloud = WordCloud(mask = icecream_mask, background_color='white', contour_width=3, contour_color='violet')\n",
    "\n",
    "# Generate the words to cloud from our data string\n",
    "wordcloud.generate(data_string)\n",
    "\n",
    "# Plot the figure, optionally ignore the axis.\n",
    "plt.figure (figsize = (8,8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! We've created a cool, ice cream -shaped wordcloud from ice cream stall reviews! Now, try to make a word cloud yourself from some other set of words! You can even try to create your own mask for the figure.\n",
    "\n",
    "Happy coding!\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note</b> \n",
    "\n",
    "If you want to define the weight of each word as a number instead of it's frequency in a text, you can generate the cloud using [`generate_from_frequencies()`](https://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html)-method. You just need to pass a dictionary as a parameter. For example you could write\n",
    "\n",
    "```python\n",
    "words = {\"Dog\":10, \"Cat\": 5, \"Cow\":5, \"Platypus\":3}\n",
    "wordcloud.generate(words)\n",
    "```\n",
    "\n",
    "This would result in a cloud, where the word \"Dog\" would be the largest and \"Platypus\" the smallest.\n",
    "\n",
    "You can save your image by writing\n",
    "\n",
    "```python\n",
    "plt.savefig(\"filename.png\")\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
